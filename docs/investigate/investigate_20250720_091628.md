# 調査レポート：タイムアウトエラーURL除外機能の実装

調査日時: 2025-07-20 09:16:28  
調査者: Claude Code  
ブランチ: feature/remove-timeout-urls

## 調査概要

WebText抽出システムにおいて、タイムアウトエラー（ERR_TIMED_OUT）が発生したサイトのエラーメッセージがテキストとして抽出される問題を調査し、該当URLをURL一覧から削除する機能の実装可能性を検証した。

## 現状分析

### 問題の具体例

Yahoo知恵袋のURL（`detail.chiebukuro.yahoo.co.jp`）へのアクセス時に、以下のようなエラーメッセージが抽出される：

```
このサイトにアクセスできませんdetail.chiebukuro.yahoo.co.jpからの応答時間が長すぎます。
次をお試しください接続を確認するプロキシとファイアウォールを確認する
Windows ネットワーク診断ツールを実行するERR_TIMED_OUT再読み込み詳細...
```

### システム構成

- **並列処理環境**: 10個のWebText_extractionフォルダで並列実行
- **共通スクリプト**: `common_scripts/`フォルダ内のスクリプトを全ワークスペースで共有
- **処理フロー**:
  1. URL検索（google_url_serch.py, yahoo_url_search.py）
  2. テキスト抽出（web_text_extractor_ver1.5.py）  
  3. 結果統合（integrated.py）
  4. 配信ファイル更新（update_delivery_file.py）

### 現在の実装状況

1. **部分的な対応済み機能**:
   - `save_results`メソッドで一部のエラーメッセージを除外
   - `integrated.py`でタイムアウトURLの検出（「（テキスト抽出タイムアウト）」のみ）

2. **未対応の問題**:
   - ブラウザ表示のタイムアウトエラー（ERR_TIMED_OUT）は除外対象外
   - URLリストファイル自体は変更されない

## 根本原因

1. **Selenium使用時のタイムアウト**:
   - 特にYahoo知恵袋などでSeleniumによるアクセス時にタイムアウトが発生
   - エラーページのHTMLがそのままテキストとして抽出される

2. **不完全なエラー検出**:
   - 現在の除外処理はプログラム内部のエラーメッセージのみ対象
   - ブラウザが表示するエラーページのテキストは検出されない

3. **URLリストの永続化**:
   - エラーが発生したURLがリストに残るため、次回実行時も同じエラーが発生

## 技術的制約と可能性

### 制約
- 並列処理環境でURLリストが個別管理されている
- タイムアウトの原因は多様（ネットワーク、サイト側の問題、robots.txt等）
- エラーメッセージの形式がブラウザによって異なる可能性

### 可能性
- ブラウザのタイムアウトエラーメッセージを検出可能
- URLリストファイルからの該当URL削除が技術的に可能
- `common_scripts/`を活用した全ワークスペースでの統一処理が可能

## 解決方針

### 1. エラー検出の改善
`web_text_extractor_ver1.5.py`の`save_results`メソッドに以下の検出条件を追加：
- 「このサイトにアクセスできません」
- 「ERR_TIMED_OUT」
- 「からの応答時間が長すぎます」

### 2. URLリスト更新機能の追加
- タイムアウトエラーが検出されたURLをリストから削除
- 元のURLリストファイルを更新する処理を実装

### 3. 実装場所
`common_scripts/web_text_extractor_ver1.5.py`に統合実装することで、全ワークスペースで統一的に処理

## 推奨実装ステップ

1. **エラー検出処理の強化**:
   - ブラウザエラーメッセージのパターンを追加
   - 検出したタイムアウトURLを記録

2. **URLリスト更新機能**:
   - `save_results`メソッド内でURLリストファイルを更新
   - バックアップ機能の実装（安全性確保）

3. **ログ機能の強化**:
   - 除外されたURLの詳細ログ
   - URLリスト更新の履歴管理

## 想定される影響

### ポジティブな影響
- エラーメッセージの混入を防止
- 処理効率の向上（無駄な再試行を回避）
- よりクリーンな抽出結果

### 考慮事項
- 一時的なネットワークエラーで有効なURLが削除される可能性
- リトライ機能の検討が必要

## 結論

タイムアウトエラーが発生したURLを自動的に除外する機能の実装は技術的に可能であり、システムの品質向上に貢献する。実装は`common_scripts/web_text_extractor_ver1.5.py`への統合が最適である。